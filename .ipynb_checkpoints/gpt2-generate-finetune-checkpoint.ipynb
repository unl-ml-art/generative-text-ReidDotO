{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7LoMj4GA4n_"
   },
   "source": [
    "#  GPT-2 Generation and Fine-Tuning\n",
    "\n",
    "This notebook explores GPT-2 (Generative Pretrained Transformer-2) from OpenAI. Read more about it [here](https://openai.com/blog/better-language-models/).\n",
    "\n",
    "Activities include:\n",
    "\n",
    "0. Setup\n",
    "1. Generate samples from pre-trained gpt-3 model\n",
    "2. Fine-tune gpt-2 on text of your choosing. \n",
    "\n",
    "Adapted by Robert Twomey (rtwomey@unl.edu) for Machine Learning for the Arts SP22 from this [google colab](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) by [Max Woolf](http://minimaxir.com). See his repo [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run once to install the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q gpt-2-simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restart the kernel and run the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KBkpRgBCBS2_"
   },
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj2IJLHP3KwE"
   },
   "source": [
    "## GPU\n",
    "\n",
    "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
    "\n",
    "You can verify which GPU is active by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUmTooTW3osf",
    "outputId": "c9fcfa4f-277d-4b3e-8974-373066dc157b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 14 15:10:35 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    26W / 250W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the memory usage (0MiB / 32510MiB) for the Tesla V100.\n",
    "You can re-rerun the above cell to see what memory your code/models are using during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wXB05bPDYxS"
   },
   "source": [
    "## Downloading GPT-2\n",
    "\n",
    "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
    "\n",
    "There are three released sizes of GPT-2:\n",
    "\n",
    "* `124M` (default): the \"small\" model, 500MB on disk.\n",
    "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
    "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
    "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
    "\n",
    "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
    "\n",
    "The next cell downloads it from Google Cloud Storage and saves it in the the current working directory at `/models/<model_name>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8wSlgXoDPCR",
    "outputId": "10fc0d7c-d18f-4e11-a2af-bfade8b537eb"
   },
   "outputs": [],
   "source": [
    "model_name = \"355M\" # largest model we can fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run once to download the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 948Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 4.20Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 2.03Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:20, 67.9Mit/s]                                 \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.35Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.23Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 5.44Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQAN3M6RT7Kj"
   },
   "source": [
    "# 1. Generate Text From The Pretrained Model\n",
    "\n",
    "If you want to generate text from the pretrained model pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`. (This is currently the only way to generate text from the 774M or 1558M models with this notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "BAe4NpKNUj2C",
    "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:11:53.050151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-14 15:11:54.112884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model models/355M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.load_gpt2(sess, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from the model\n",
    "The follow cell samples from gpt-2, using the provided prefix (seed) and other parameters. It starts the TF session and generates the samples.\n",
    "\n",
    "Try changing the parameters below to change the output: \n",
    "- `prefix` is the prompt. This will be the starting string/seed for your generation. Use your own text. \n",
    "- `temperature` sets the variability/randomness of the output. Range 0.0-1.0\n",
    "- `length` sets the lenght of output (in tokens). max is 1024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "-xInIZKaU104",
    "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today, I will eat it, but I'll do it cold. I'll eat it cold, but I'll eat it hot. I'll eat it hot, but I'll eat it cold.\"\n",
      "\n",
      "This kind of approach will likely be the case as well, because if he wanted to spend more time eating, he would eat more. However, if he wanted to eat more, he would eat more.\n",
      "\n",
      "On the other hand, if he were to eat less, he would eat less.\n",
      "\n",
      "However\n",
      "====================\n",
      "Today, I will eat a cake for a birthday or anniversary,\" he said, smiling. \"I was surprised how much people liked it.\"\n",
      "\n",
      "The cake was inspired by an old friend, Mr. Guccione, who is in his 60s. Mr. Guccione, who is the owner of a bakery in the Bronx, said he went to see the show on Wednesday night and was in the middle of eating when he saw the cake.\n",
      "\n",
      "\"He said, 'Oh my gosh, this\n",
      "====================\n",
      "Today, I will eat with my family, go to the movies, and take a shower. I will not be afraid to express myself with my body, my words, and my thoughts. I will not be afraid to say what I believe and what I think. I will not be afraid to make my own choices and make my own choices with my body, with my words, and with my thoughts. I will not be afraid to live my life. I will not be afraid to love myself.\n",
      "\n",
      "I will be\n",
      "====================\n",
      "Today, I will eat everything. I will drink every cup of coffee. I will eat every meal. I will drink every bottle of wine. I will have no regrets.\n",
      "\n",
      "\"I will eat everything, drink every cup of coffee, and drink every meal. I will eat every meal, drink every cup of coffee, and eat every meal. I will eat every meal, drink every cup of coffee, and eat every meal. I will eat every meal, drink every cup of coffee, and eat every meal.\n",
      "====================\n",
      "Today, I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "I will eat anything I want on a regular basis.\n",
      "\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              model_name=model_name,\n",
    "              prefix=\"Today, I will eat\",\n",
    "              length=100,\n",
    "              temperature=0.7,\n",
    "              top_p=0.9,\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities\n",
    "- try varying the prefix. \n",
    "  - what length of prefix works best with the given model? \n",
    "  - how does the choice of prefix change the format/form of the output.\n",
    "- try varying the temperature.\n",
    "- try loading the different sized models (124M, 355M, 774M, 1558M) and generate text without changing the other parameters. \n",
    "  - Do you notice any qualitative differences in the output? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fine-Tuning GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already generated with gpt2, you need to reset the tf graph and gpt2 session. Otherwise, we create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeXshJM-Cuaf",
    "outputId": "a3c75caa-917b-4818-ca2d-d78610d8b6f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:13:41.791973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"355M\" # same model as selected above\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# check if sess exists (e.g. if we ran section 1 above)\n",
    "var_exists = 'sess' in locals() or 'sess' in globals()\n",
    "\n",
    "if not var_exists:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeeSKtNWUedE"
   },
   "source": [
    "## Upload a text file\n",
    "For this, we will use a text file you provide to finetune (continue training) GPT-2. You can use any plain text (.txt) file. \n",
    "\n",
    "Simply drag and dropy our text file into the file browser at left. \n",
    "\n",
    "Once you have uploaded your file, update the file name in the cell below, then run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6OFnPCLADfll"
   },
   "outputs": [],
   "source": [
    "file_name = \"yardEps.txt\" # your file here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdpZQXknFNY3"
   },
   "source": [
    "## Run the finetuning\n",
    "\n",
    "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
    "\n",
    "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every `save_every` steps (can be changed) and when the cell is stopped.\n",
    "\n",
    "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them. If your input text is smaller, training might proceed more quickly.\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
    "\n",
    "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
    "* **`sample_every`**: Number of steps to print example output\n",
    "* **`print_every`**: Number of steps to print training progress.\n",
    "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
    "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
    "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For larger models, the recommended finetune() parameters are:\n",
      "\tuse_memory_saving_gradients = True\n",
      "\tonly_train_transformer_layers = True\n",
      "\taccumulate_gradients = 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:14:44.289999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30979 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/355M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 146492 tokens\n",
      "Training...\n",
      "[10 | 25.68] loss=2.61 avg=2.61\n",
      "[20 | 45.45] loss=2.65 avg=2.63\n",
      "[30 | 65.23] loss=2.60 avg=2.62\n",
      "[40 | 84.99] loss=2.47 avg=2.58\n",
      "[50 | 104.76] loss=2.44 avg=2.55\n",
      "[60 | 124.55] loss=2.56 avg=2.55\n",
      "[70 | 144.31] loss=2.48 avg=2.54\n",
      "[80 | 164.07] loss=2.42 avg=2.53\n",
      "[90 | 183.83] loss=2.54 avg=2.53\n",
      "[100 | 203.60] loss=2.48 avg=2.52\n",
      "======== SAMPLE 1 ========\n",
      " talking\n",
      "26:26\n",
      "uh we don't need to do\n",
      "26:28\n",
      "this because we\n",
      "26:29\n",
      "aren't getting paid\n",
      "26:30\n",
      "we know what we're getting\n",
      "26:31\n",
      "and that we have to go to this\n",
      "26:33\n",
      "event and we have to sign up\n",
      "26:34\n",
      "and we should give something back\n",
      "26:36\n",
      "that's just kind of a [ __ ] thing\n",
      "26:38\n",
      "i'd love to see that happening but\n",
      "26:39\n",
      "uh and it's a crazy idea\n",
      "26:41\n",
      "you know like you've gotta be out of\n",
      "26:43\n",
      "your mind at all times\n",
      "26:45\n",
      "and you get mad about the whole\n",
      "26:46\n",
      "thing but like this thing is a\n",
      "26:48\n",
      "cool idea but but like oh well\n",
      "26:50\n",
      "it's crazy because you're\n",
      "26:52\n",
      "going out to a party\n",
      "26:53\n",
      "you'll be like hey i don't feel\n",
      "26:55\n",
      "you know\n",
      "26:57\n",
      "there's this party and like\n",
      "26:58\n",
      "that's happening and someone says\n",
      "26:59\n",
      "like dude i think it's a good idea to\n",
      "27:01\n",
      "come for the whole night\n",
      "27:04\n",
      "or like the whole weekend and there\n",
      "27:05\n",
      "is still no payouts to people who\n",
      "27:07\n",
      "do this i think yeah that's\n",
      "27:09\n",
      "cool\n",
      "27:11\n",
      "i think it's not a [ __ ] thing\n",
      "27:13\n",
      "but and and who's gonna care if\n",
      "27:15\n",
      "people don't take the money\n",
      "27:18\n",
      "and because i didn't want that at\n",
      "27:20\n",
      "first when jesus was [ __ ] i\n",
      "27:22\n",
      "was like do this instead oh\n",
      "27:23\n",
      "i'm a lot happier because\n",
      "27:25\n",
      "[song cuts to black]\n",
      "27:27\n",
      "that's so true yeah and that's\n",
      "27:29\n",
      "what i'm like thinking about when\n",
      "27:31\n",
      "i'm at work\n",
      "27:33\n",
      "and i'm like i don't want\n",
      "27:35\n",
      "people to be angry about it like its\n",
      "27:37\n",
      "not me i'm a pretty busy person\n",
      "27:39\n",
      "and i would love to have to\n",
      "27:42\n",
      "pay for all that my friend\n",
      "27:44\n",
      "was going to do i am not so good\n",
      "27:45\n",
      "with that he just did a big\n",
      "27:46\n",
      "party and i go there and he's\n",
      "27:49\n",
      "like jesus has a party right there\n",
      "27:51\n",
      "and he's like i know i know jesus has a\n",
      "27:53\n",
      "party and i'm like how does that happen\n",
      "27:56\n",
      "i have to pay for it and he's like\n",
      "27:58\n",
      "you know what that is he's like\n",
      "28:00\n",
      "it's like he's the boss of this\n",
      "28:01\n",
      "party and he's like you're supposed\n",
      "28:02\n",
      "to put us up here but you're\n",
      "28:04\n",
      "not the boss yeah and it's like\n",
      "28:06\n",
      "like it's like he's like i know\n",
      "28:07\n",
      "you're supposed to pay us and i'm like\n",
      "28:09\n",
      "yeah but he's like he's like well\n",
      "28:10\n",
      "it's like a weird situation where\n",
      "28:12\n",
      "there's this big corporation\n",
      "28:13\n",
      "and it's like no it's just like me\n",
      "28:16\n",
      "and [ __ ] and everybody it's\n",
      "28:18\n",
      "like yeah it's a big corporation\n",
      "28:20\n",
      "and they all\n",
      "28:23\n",
      "just go off and do other stuff\n",
      "28:24\n",
      "and jesus has this thing going on\n",
      "28:26\n",
      "and he's like i think they've\n",
      "28:28\n",
      "started to pay me for our\n",
      "28:30\n",
      "party and it's like wait the\n",
      "28:31\n",
      "corporation paid for it and it's\n",
      "28:33\n",
      "like i know it's just like they're\n",
      "28:34\n",
      "taking care of it you know\n",
      "28:35\n",
      "and we're like whoa jesus\n",
      "28:36\n",
      "who pays the people? that's just\n",
      "28:38\n",
      "that's ridiculous it's no you like\n",
      "28:39\n",
      "jesus pays the people\n",
      "28:41\n",
      "he's taking care of it that's why\n",
      "28:42\n",
      "i'm so mad about it\n",
      "28:44\n",
      "i was like but i was like what\n",
      "28:46\n",
      "if i wasn't like like this is so\n",
      "28:48\n",
      "hard yeah i do have things i\n",
      "28:50\n",
      "do though and i think that's that\n",
      "28:51\n",
      "part of being super super nice\n",
      "\n",
      "[110 | 236.34] loss=2.39 avg=2.51\n",
      "[120 | 256.10] loss=2.42 avg=2.50\n",
      "[130 | 275.87] loss=2.35 avg=2.49\n",
      "[140 | 295.67] loss=2.30 avg=2.48\n",
      "[150 | 315.43] loss=2.28 avg=2.46\n",
      "[160 | 335.21] loss=2.36 avg=2.46\n",
      "[170 | 354.98] loss=2.24 avg=2.44\n",
      "[180 | 374.74] loss=2.35 avg=2.44\n",
      "[190 | 394.50] loss=2.26 avg=2.43\n",
      "[200 | 414.26] loss=2.33 avg=2.42\n",
      "Saving checkpoint/run1/model-200\n",
      "======== SAMPLE 1 ========\n",
      " it's the first one to get an update and he's like\n",
      "57:47\n",
      "what a funny guy in a funny moment and then he's like\n",
      "57:49\n",
      "what are you talking about what are you talking\n",
      "57:52\n",
      "about what is he talking\n",
      "57:53\n",
      "what the hell what's all this\n",
      "57:55\n",
      "what is it is what are you talking to me\n",
      "57:57\n",
      "dude what the [ __ ]\n",
      "57:58\n",
      "it's a podcast where you're at the piano and\n",
      "58:00\n",
      "the piano player is like hey i'd like to\n",
      "58:02\n",
      "do a video with you and you like to do a\n",
      "58:03\n",
      "video with him so you just play for a while\n",
      "58:05\n",
      "then you play it for like another 20 minutes\n",
      "58:07\n",
      "or something so you have to wait while he\n",
      "58:09\n",
      "plays and like so you make it a little\n",
      "58:11\n",
      "better you're not there but his [ __ ]\n",
      "58:12\n",
      "is like oh yeah\n",
      "58:13\n",
      "and the next song it's just he keeps\n",
      "58:14\n",
      "playing while i'm [ __ ] playing\n",
      "58:15\n",
      "like\n",
      "58:29\n",
      "like oh this is great what happened you\n",
      "58:31\n",
      "won the [ __ ] and then just when you get\n",
      "58:33\n",
      "over the 10 seconds or what it's like just to\n",
      "58:35\n",
      "make it like the [ __ ] are doing what's\n",
      "58:38\n",
      "that for you i was like dude\n",
      "58:40\n",
      "you lost to a video game player uh yeah\n",
      "58:42\n",
      "but now the dude's like you look like you\n",
      "58:44\n",
      "got a girlfriend we went out i was like\n",
      "58:46\n",
      "yeah\n",
      "58:47\n",
      "yeah you look like\n",
      "58:48\n",
      "yeah i didn't look at her i was you\n",
      "58:49\n",
      "were you wearing some panties on the way home\n",
      "58:50\n",
      "because this is the first episode of\n",
      "58:51\n",
      "the [ __ ] and the next thing you know\n",
      "58:53\n",
      "you're like well I'm no longer\n",
      "58:54\n",
      "playing a video game and i do in the\n",
      "58:55\n",
      "car\n",
      "58:57\n",
      "and you're like uh what is your girlfriend\n",
      "58:59\n",
      "that's right because what were you doing\n",
      "59:01\n",
      "you had to i had to do this too\n",
      "59:03\n",
      "it just came down to like like you're\n",
      "59:05\n",
      "dude i've got to do this it's too\n",
      "59:08\n",
      "hard and you look in the mirror and it's\n",
      "59:09\n",
      "like i just can't you're like no you i\n",
      "59:11\n",
      "looked through the bathroom where i did\n",
      "59:13\n",
      "it just looks like every single one of\n",
      "59:14\n",
      "it's so weird and then after like a\n",
      "59:16\n",
      "short moment where it's like i just like\n",
      "59:18\n",
      "take a walk and it's like there's only\n",
      "59:20\n",
      "20 seconds and you're like yeah okay and then\n",
      "59:22\n",
      "where it starts to get to you no and then i\n",
      "59:25\n",
      "go i have a problem we're at the zoo\n",
      "59:27\n",
      "and i'm like\n",
      "59:29\n",
      "you know when you were like\n",
      "59:30\n",
      "it's like that's\n",
      "59:31\n",
      "like that's how you guys all\n",
      "59:32\n",
      "gotta work it out yeah\n",
      "59:36\n",
      "it's like\n",
      "59:37\n",
      "it's like i'm like okay it's like that's\n",
      "59:39\n",
      "just how it is it's like that's true too\n",
      "59:41\n",
      "all the time\n",
      "59:42\n",
      "that's funny because i would never do\n",
      "59:44\n",
      "that i think it's like uh like the\n",
      "59:46\n",
      "you know what it's funny that i don't\n",
      "59:47\n",
      "it feels kind of funny\n",
      "59:48\n",
      "because like in video games i just go\n",
      "59:48\n",
      "there i always have like a random\n",
      "59:50\n",
      "random piece of stuff and i just like i\n",
      "59:52\n",
      "just like i just like go there and i\n",
      "59:53\n",
      "[ __ ] them and then i just\n",
      "59:55\n",
      "just keep hitting the space bar like a\n",
      "59:56\n",
      "mushroom\n",
      "59:57\n",
      "while i'm playing a video game and i\n",
      "59:58\n",
      "just [ __ ] out i just i have like a\n",
      "60:02\n",
      "randomly generated [ __ ] because i\n",
      "60:05\n",
      "always play the [ __ ] game and i don't\n",
      "60:06\n",
      "make a friend for like five minutes\n",
      "60:07\n",
      "and then i like just like get back to\n",
      "60:09\n",
      "playing\n",
      "\n",
      "[210 | 449.52] loss=2.19 avg=2.41\n",
      "[220 | 469.32] loss=2.28 avg=2.40\n",
      "[230 | 489.14] loss=2.23 avg=2.39\n",
      "[240 | 508.91] loss=2.15 avg=2.38\n",
      "[250 | 528.67] loss=2.22 avg=2.38\n",
      "Saving checkpoint/run1/model-250\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages/tensorflow/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name=model_name,\n",
    "              steps=250,\n",
    "              restore_from='fresh', # change to 'latest' to resume\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              learning_rate=1e-5,\n",
    "              sample_every=100,\n",
    "              save_every=200\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXSuTNERaw6K"
   },
   "source": [
    "## Notes on finetuning\n",
    "\n",
    "Keep an eye on the loss, and how quickly it is dropping. A too-rapid drop in loss could be a sign of overfitting, and a learning rate (lr) that is too high. \n",
    "\n",
    "After the model is trained, you can download the checkpoint folder to save your work. Training checkpoints are saved to `checkpoint/run1` (or whatever you chose for the run name above).\n",
    "\n",
    "You can compress it to a rar file and download that. Ask the instructor how.\n",
    "\n",
    "You're done! Feel free to go to the Generate Text From The Trained Model section to generate text based on your retrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Finetune some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already generated with gpt2, you need to reset the tf graph and gpt2 session. Otherwise, we create a new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "aeXshJM-Cuaf",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "a3c75caa-917b-4818-ca2d-d78610d8b6f2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 11:58:52.396304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14629 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:da:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#model_name = \"355M\" # same model as selected above\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# check if sess exists (e.g. if we ran section 1 above)\n",
    "var_exists = 'sess' in locals() or 'sess' in globals()\n",
    "\n",
    "if not var_exists:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "To fine-tune some more, run the following. Be sure to increase the number of steps (if it was `500` before, change to `1000` to train for 500 more. the number is cumulative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-200\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-200\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 36647 tokens\n",
      "Training...\n",
      "Saving checkpoint/run1/model-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== SAMPLE 1 ========\n",
      " like you don't need the water for the rest of the day\n",
      "50:39\n",
      "so you get to say some words like that that\n",
      "50:45\n",
      "you are such a sweetie\n",
      "50:47\n",
      "you do you guys i'm so excited\n",
      "50:49\n",
      "like it's like a dream come true\n",
      "50:51\n",
      "and this is like my first time taking this\n",
      "50:52\n",
      "guy on a hike i didn't know where he was\n",
      "50:54\n",
      "he's just so so nice and i'm just\n",
      "50:56\n",
      "like this is my first time you guys have a\n",
      "51:00\n",
      "seen me this whole trip i can't believe i\n",
      "51:02\n",
      "think you're the most handsome dude you\n",
      "51:04\n",
      "see just like i don't know how i feel and\n",
      "51:06\n",
      "this is a dream come true thing because\n",
      "51:08\n",
      "like i don't know and i feel like yeah i'm\n",
      "51:10\n",
      "i'm just like this is not because you're\n",
      "51:12\n",
      "that bad a bunch you know how like some\n",
      "51:14\n",
      "savage dude you guys know because you're like\n",
      "51:16\n",
      "your friend we're trying to get you to\n",
      "51:18\n",
      "go join us and we're trying to get you\n",
      "51:19\n",
      "to join our team because you're just\n",
      "51:21\n",
      "such an awesome guy i can't wait\n",
      "51:23\n",
      "i'm just\n",
      "51:24\n",
      "this is such a bad dream what\n",
      "51:27\n",
      "if i didn't stay here with you and you\n",
      "51:29\n",
      "then i'm sure you would think if i\n",
      "51:30\n",
      "leave you are the sun i would really love\n",
      "51:33\n",
      "to be here with you and i couldn't imagine\n",
      "51:36\n",
      "not leaving you\n",
      "51:38\n",
      "i think that if i left and it wasn't for\n",
      "51:42\n",
      "you and the family\n",
      "51:43\n",
      "and if i left you would be so lost that\n",
      "51:46\n",
      "you would have to think about how you\n",
      "51:49\n",
      "ever would have been without you\n",
      "51:51\n",
      "and how you and the family would have felt\n",
      "51:54\n",
      "like i love you if i had to\n",
      "51:56\n",
      "but do you know what that would be like i\n",
      "51:58\n",
      "thought if i was with you\n",
      "52:02\n",
      "but i had this dream and i'm like\n",
      "52:03\n",
      "i'm like like a dream come true where\n",
      "52:04\n",
      "you\n",
      "52:05\n",
      "you're like you're so soft and like a\n",
      "52:07\n",
      "doodle it's like a dream come true\n",
      "52:09\n",
      "doodle but like a dream come true and i\n",
      "52:10\n",
      "thought maybe i should put my hand up the\n",
      "52:12\n",
      "elbow and just\n",
      "52:13\n",
      "make sure you get into your and like and\n",
      "52:15\n",
      "you just make sure you are okay and i\n",
      "52:17\n",
      "was trying to pull him in that direction but\n",
      "52:19\n",
      "it just didn't seem to work\n",
      "52:21\n",
      "is that right uh and just you all up a\n",
      "52:23\n",
      "lumia and i was like i's right i pulled my\n",
      "52:25\n",
      "hotness up and it would feel like and i\n",
      "52:28\n",
      "was trying to pull him in and to my\n",
      "52:30\n",
      "he wasn't there he was just like\n",
      "52:32\n",
      "i'm literally laying on top of him i was\n",
      "52:36\n",
      "like i'm like he's falling and i think\n",
      "52:39\n",
      "i'm like i'm on like a train like and\n",
      "52:41\n",
      "so i was just trying to pull him in with\n",
      "52:43\n",
      "that in my head like and i'm like what is\n",
      "52:44\n",
      "is this and i don't know how i feel because\n",
      "52:46\n",
      "it was just an i didn't think\n",
      "52:49\n",
      "it was something serious and\n",
      "52:51\n",
      "i did feel it it was just like a\n",
      "52:52\n",
      "little piece of me that was holding\n",
      "52:55\n",
      "him in and i was like so that's it i feel what\n",
      "52:57\n",
      "was\n",
      "52:59\n",
      "is his i just don't i didn't think\n",
      "53:03\n",
      "it was something serious and i think it was\n",
      "53:05\n",
      "crazy he was like\n",
      "53:06\n",
      "suddenly he's on top\n",
      "53:08\n",
      "and he's floating in mid air\n",
      "53:10\n",
      "and i just was like is what is this\n",
      "53:12\n",
      "something serious and and i was like yeah\n",
      "53:14\n",
      "this wasn't too far ago\n",
      "53:16\n",
      "i was like i was like\n",
      "53:19\n",
      "i thought like i'm like this is it when\n",
      "53\n",
      "\n",
      "[210 | 22.49] loss=2.11 avg=2.11\n",
      "[220 | 30.03] loss=2.12 avg=2.11\n",
      "[230 | 37.56] loss=1.93 avg=2.05\n",
      "[240 | 45.08] loss=2.04 avg=2.05\n",
      "[250 | 52.61] loss=1.92 avg=2.02\n",
      "[260 | 60.16] loss=1.93 avg=2.01\n",
      "[270 | 67.70] loss=1.91 avg=1.99\n",
      "[280 | 75.24] loss=1.81 avg=1.97\n",
      "[290 | 82.82] loss=1.83 avg=1.95\n",
      "[300 | 90.37] loss=1.56 avg=1.91\n",
      "Saving checkpoint/run1/model-300\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow-gpu/envs/tensorflow-gpu-2.6.0-py39/lib/python3.9/site-packages/tensorflow/python/training/saver.py:969: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "======== SAMPLE 1 ========\n",
      " and the other was, okay. He's a really great big guy now.\n",
      "\n",
      "Kiara: Well, it was kind of weird because that's just a big dude.\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "Hanna:\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Pictures]\n",
      "\n",
      "[Stream the clip]\n",
      "\n",
      "[Script Offer]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Streaming]\n",
      "\n",
      "\n",
      "[Video pauses]\n",
      "\n",
      "Yours faithfully\n",
      "\n",
      "[Unrelated: whoa]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Music]\n",
      "\n",
      "\n",
      "[Unrelated: a dude who just can't keep up with women sounds like a dude like a dude like a dude]\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Whisper]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Music]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "\n",
      "[Applause]\n",
      "\n",
      "[Laughter]\n",
      "\n",
      "[Laughter]<|endoftext|>[Spoiler] [Spoiler] [Spoiler]\n",
      "\n",
      "[img]https://mega.nz/#!p4zMwzLg!d1hY3bLzqR3w3u3LkqH3Zy3i3mk6zLm3uT6s9dVt3cGVzc\n",
      "\n",
      "[img]https://img.meleebricks.com/upload.php?v=12388901[/img]\n",
      "\n",
      "[img]https://cdn4all.wordpress.com/2013/02/13/skeleton-gorgeous/\n",
      "\n",
      "[img]https://img57bnd.cloudfront.net/files/a668977b78a8927e55d7431e5534f78e78.jpg[/img]\n",
      "\n",
      "[img]https://cdn66.files.wordpress.com/2013/11/15/shadow_walker-guides-guide-1.pdf[/image]\n",
      "\n",
      "\n",
      "[IMG]https://medium.com/@shadowwalkerguides/i-am-pagan-wizard-pumpkin-for-championship-featured\n",
      "\n",
      "[IMG]https://medium.com/@shadowwalkerguides/i-am-pagan-wizard-pumpkin-for-championship-featured<|endoftext|>[bitcoin-dev]\n",
      "\n",
      "by\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "[\n",
      "\n",
      "]\n",
      "\n",
      "// BIP66: no need to be a crypto-currency expert to know about it\n",
      "\n",
      "[ __ ]\n",
      "\n",
      "[ __ ]\n",
      "\n",
      "[ __ ]\n",
      "\n",
      "[ ]\n",
      "\n",
      "// no need to believe bitcoin is a black box because it's\n",
      "\n",
      "//\n",
      "\n",
      "// [ __ ]\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "//\n",
      "\n",
      "// # for i in range ( 50 )\n",
      "\n",
      "# ifdef __cplusplus\n",
      "\n",
      "# include < bitcoin.h\n",
      "\n",
      "# include < glibc.h\n",
      "\n",
      "# include < stddef.h\n",
      "\n",
      "# include < kw.\n",
      "\n",
      "[310 | 106.49] loss=1.64 avg=1.89\n",
      "[320 | 114.03] loss=1.70 avg=1.87\n",
      "[330 | 121.57] loss=1.63 avg=1.85\n",
      "[340 | 129.10] loss=1.47 avg=1.82\n",
      "[350 | 136.64] loss=1.36 avg=1.79\n",
      "[360 | 144.18] loss=1.53 avg=1.77\n",
      "[370 | 151.72] loss=1.38 avg=1.75\n",
      "[380 | 159.26] loss=1.42 avg=1.73\n",
      "[390 | 166.80] loss=1.30 avg=1.70\n",
      "[400 | 174.34] loss=1.33 avg=1.68\n",
      "Saving checkpoint/run1/model-400\n",
      "======== SAMPLE 1 ========\n",
      "so as a general rule things need to be the same but this actually didn't happen in a popular anime and it does just so i wanted to make something the other day which is super short it's this anime called In the Future and and and the episode starts with this this guy named Shigemitsu is this 15 year old old girl that wants to be a comic book artist and she comes up to her and she's like this is this one guy she's like what is this this and she's she's she's she's this she's she's she's i like this is it's it's okay and he just keeps showing up and he's the star and the no one knows what and then he's like\n",
      "babe that's right and they like they like get that in your head\n",
      "crazy that's crazy\n",
      "i'll be there because why doesn't ari have a role in this is wrong episode two it's just so absurd\n",
      "crazy it's such and i'm still so so so so so so such ari no it's just such and then someone complimentes him on Twitter\n",
      "but once they compliment it's always absurd and then eventually aria gets on it's just someone complimenting someone on twitter\n",
      "brave you i like it's funny no but the funny is the funny is that this anime called and the gang comes out of the forest and uh they have this guy named Heisenberg with the gang\n",
      "he starts to ask like the question\n",
      "i was doing my regular comic this time and all i had to do was ask it the question the comic asked the question the comic asked the comic got me to do the story\n",
      "i was drawing and i was drawing like two pages after like a drawing like three or four and this dude has i get to draw\n",
      "i'm like this is this dude is drawing like two pages in a row\n",
      "this is the i'm like\n",
      "this is like this is a bunch of dead dude this is the dude i am drawing like dead and i'm like okay this is the guy that drew this comic\n",
      "i'm drawing like dead this is this dead dude dead and what are you doing this is that you that you this is dead and i you that you that you that you this is dead and i\n",
      "this is dead this is this dead this is i'm this is this is i'm\n",
      "your\n",
      "i'm like this is dead this is this dead this is this dead you are i'm\n",
      "you are dead this is all\n",
      "listen to me when the times come i'm\n",
      "listen to me when the times come\n",
      "bravely but with hearts in it\n",
      "bravely but with hearts in it\n",
      "bravely but with hearts in it\n",
      "bravely but with hearts in it\n",
      "bravely but with hearts in it\n",
      "bravely yet with hearts in it\n",
      "bravely yet with hearts in it\n",
      "bravely yet with hearts in it\n",
      "i look here what is it who do you like most and then you\n",
      "like who do you like most oh look here i like all the people who\n",
      "like people oh look they're all safe come on i like\n",
      "\n",
      "what's the\n",
      "i like it's all\n",
      "listen here\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen\n",
      "listen i'm just gonna say this all of them and i'm just saying [ __ ] and you guys\n",
      "here i'm gonna\n",
      "it was just as [ __ ] it was before it is now and\n",
      "i'm just gonna i'm just gonna say this and there this is\n",
      "\n",
      "what i thought and we'll get inside it and we'll\n",
      "get inside it and it was for a living who did\n",
      "what you did and i was like for god\n",
      "um\n",
      "oh\n",
      "oh yeah this is so it is oh yeah yeah\n",
      "wow yeah what is up\n",
      "um yeah yeah no no oh how is everything\n",
      "\n",
      "um yeah okay okay\n",
      "wow uh oh\n",
      "um yeah i'm sorry no [ __ ] no no no wait what's up\n",
      "what's up\n",
      "um [ __ ] here [ __ ] you are\n",
      "um hello [ __ ] here are the things\n",
      "this [ __ ] is\n",
      "um [ __ ] everything\n",
      "um [ __ ] is he right this is the weirdo he\n",
      "\n",
      "is he's just this [ __ ] this is the weirdo what's\n",
      "\n",
      "done's how long have we talked done this\n",
      "this is how long have we talked talked talked\n",
      "\n",
      "done so far this is how far are we this is the weirdo\n",
      "\n",
      "this is where are we\n",
      "through the nose for a beat yeah yeah\n",
      "through the nose for a beat yeah yeah\n",
      "through the nose for a beat yeah yeah\n",
      "through the nose for a beat yeah\n",
      "\n",
      "[410 | 190.73] loss=1.35 avg=1.66\n",
      "[420 | 198.27] loss=1.20 avg=1.64\n",
      "[430 | 205.82] loss=1.14 avg=1.62\n",
      "[440 | 213.38] loss=1.21 avg=1.60\n",
      "[450 | 220.92] loss=0.94 avg=1.57\n",
      "[460 | 228.45] loss=0.93 avg=1.54\n",
      "[470 | 235.99] loss=0.87 avg=1.51\n",
      "[480 | 243.53] loss=0.80 avg=1.48\n",
      "[490 | 251.06] loss=0.85 avg=1.46\n",
      "[500 | 258.60] loss=0.75 avg=1.43\n",
      "Saving checkpoint/run1/model-500\n",
      "======== SAMPLE 1 ========\n",
      "\n",
      "14:45\n",
      "because like he's not dead\n",
      "14:46\n",
      "yeah the game you're in the middle of is\n",
      "14:47\n",
      "like in the middle of real world and\n",
      "14:49\n",
      "you're in a shop and you shop shop kind\n",
      "14:51\n",
      "of feels like he's this and so this is\n",
      "14:53\n",
      "like the ultimate porn cartoon\n",
      "14:56\n",
      "you go into the shop and you shop shop shop\n",
      "14:58\n",
      "you look around for like like minutes like you\n",
      "15:01\n",
      "don't even even touch anything or\n",
      "15:03\n",
      "just be so kind and so very sorry\n",
      "15:06\n",
      "you're dead wrong you're dead wrong\n",
      "15:09\n",
      "i'm dead soft on dead wrong so dead\n",
      "15:11\n",
      "right back to you\n",
      "15:12\n",
      "goodbye\n",
      "15:13\n",
      "i'm dead simple on dead wrong so dead\n",
      "15:18\n",
      "is a terrible name\n",
      "15:21\n",
      "i love it\n",
      "15:24\n",
      "i don't like it\n",
      "15:26\n",
      "i have no idea what corpse sounds\n",
      "15:28\n",
      "i think is\n",
      "15:30\n",
      "at all\n",
      "16:00\n",
      "i think corpse is a terrible name\n",
      "16:02\n",
      "but corpse sounds different to corpse anyway\n",
      "16:06\n",
      "cause we're the same people and corpse\n",
      "16:08\n",
      "just feels different because i'm kind of\n",
      "16:09\n",
      "a human anyway and because i live in\n",
      "16:10\n",
      "sauceauce the other day and i just\n",
      "16:11\n",
      "saw this corpse shop is the first thing you\n",
      "16:12\n",
      "think about when you go to the shop and you\n",
      "16:13\n",
      "think are are all fake i\n",
      "16:14\n",
      "solution is it not so much but just go back\n",
      "16:15\n",
      " to when you had you shave your\n",
      "16:16\n",
      "idiot mom's pussy and you see it and\n",
      "16:18\n",
      "you look dead surprised because you haven't\n",
      "16:19\n",
      "happened before and you just go right\n",
      "16:20\n",
      "it's not like mom not to bro back that\n",
      "16:21\n",
      "up you know what mom always says\n",
      "16:22\n",
      "like this is the best analogy i've\n",
      "16:23\n",
      "guys have had where like they get like that\n",
      "16:24\n",
      "while\n",
      "16:25\n",
      "happening they're like fuck yeah and they\n",
      "16:27\n",
      "say\n",
      "16:28\n",
      "then you think about how like her daddy\n",
      "16:31\n",
      "was like [ __ ]\n",
      "16:33\n",
      "dude is like [ __ ]\n",
      "16:34\n",
      "something different happens and he's like oh\n",
      "16:36\n",
      "him yeah\n",
      "16:37\n",
      "you know what he was like [ __ ]\n",
      "16:38\n",
      "everything that momentized yeah\n",
      "16:39\n",
      "no\n",
      "16:40\n",
      "they'll never know what they saw no\n",
      "16:42\n",
      "testimonials will they never know what\n",
      "16:43\n",
      "this is right up their level yeah\n",
      "16:44\n",
      "damn good thing they did it like [ __ ] it\n",
      "16:46\n",
      "didn't really it was good that they went out\n",
      "16:48\n",
      "of their way to like not trip, but you\n",
      "16:50\n",
      "don't just shut the [ __ ] up dude\n",
      "16:52\n",
      "yeah you know what they said really well\n",
      "16:53\n",
      "meant and derick is he's right\n",
      "16:55\n",
      "he was saying that to no one really like\n",
      "16:57\n",
      "but him and the world\n",
      "16:58\n",
      "it's not like that at all it's like yeah\n",
      "17:01\n",
      "well it's just like whatever\n",
      "17:03\n",
      "guy said no and now we're going somewhere\n",
      "17:05\n",
      "it's just not practical\n",
      "17:06\n",
      "what if you had uh your phone on your\n",
      "17:08\n",
      "mic you go into your living room and\n",
      "17:09\n",
      "my oh my this is the song that's playing\n",
      "17:11\n",
      "on music that my husband plays on\n",
      "17:12\n",
      "my living room rollers three at a time\n",
      "17:15\n",
      "and i get on shuffle mode and just\n",
      "17:16\n",
      "playing the song the other day and my\n",
      "17:18\n",
      "purse was full of dipper's around the dipper\n",
      "17:20\n",
      "amount of times like the amount of times\n",
      "17:21\n",
      "i've just happened to get dipper whenever\n",
      "17:22\n",
      "i was like oh gummy is dipper like in the\n",
      "17:23\n",
      "menu that says um where's my cart right\n",
      "17:25\n",
      "through it?\n",
      "17:26\n",
      "it's a funny thing because we used to get di\n",
      "17:27\n",
      "deples just like the two of us sucking\n",
      "17:28\n",
      "phrs out oh gilard i get it\n",
      "\n",
      "[510 | 274.82] loss=0.80 avg=1.41\n",
      "[520 | 282.35] loss=0.56 avg=1.38\n",
      "[530 | 289.89] loss=0.70 avg=1.35\n",
      "[540 | 297.42] loss=0.59 avg=1.33\n",
      "[550 | 304.97] loss=0.49 avg=1.30\n",
      "[560 | 312.51] loss=0.49 avg=1.27\n",
      "[570 | 320.07] loss=0.51 avg=1.25\n",
      "[580 | 327.61] loss=0.42 avg=1.22\n",
      "[590 | 335.14] loss=0.36 avg=1.19\n",
      "[600 | 342.68] loss=0.32 avg=1.17\n",
      "Saving checkpoint/run1/model-600\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name=model_name,\n",
    "              steps=500,\n",
    "              restore_from='latest', # change to 'latest' to resume\n",
    "              run_name='run1',\n",
    "              print_every=10,\n",
    "              learning_rate=1e-5,\n",
    "              sample_every=100,\n",
    "              save_every=100\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClJwpF_ACONp"
   },
   "source": [
    "# 3. Generate Text From The Finetuned Model\n",
    "\n",
    "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RNY6RBI9LmL",
    "outputId": "82574eaa-d39a-4665-b611-e5172848da57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:20\n",
      "anonymous\n",
      "17:21\n",
      "he is like yeah yeah\n",
      "17:24\n",
      "i think he's looking at a map\n",
      "17:26\n",
      "of his yard and you know he's thinking\n",
      "17:28\n",
      "about like four different people in the yard\n",
      "17:30\n",
      "and he he's like that looks a lot like\n",
      "17:32\n",
      "technically he's right he's right\n",
      "17:34\n",
      "but he's like\n",
      "17:35\n",
      "his yard is a lot like like a place\n",
      "17:37\n",
      "where you would eat at that time of night\n",
      "17:39\n",
      "and then you would like go to the\n",
      "17:40\n",
      "house and then you'd go to that yard\n",
      "17:42\n",
      "and then you'd eat and then you'd get\n",
      "17:44\n",
      "back to it\n",
      "17:46\n",
      "and then you'd get home but then\n",
      "17:48\n",
      "then you'd like go to bed at night and\n",
      "17:50\n",
      "then you'd go to bed at night\n",
      "17:52\n",
      "and then you'd go to bed at night\n",
      "17:54\n",
      "and then you'd wake up at night and\n",
      "17:56\n",
      "then you'd wake up at night and then\n",
      "17:58\n",
      "you'd wake up at night and then you'd\n",
      "18:00\n",
      "get to bed at night and then you'd get\n",
      "18:01\n",
      "to bed at night\n",
      "18:03\n",
      "and then you'd get up at night and then\n",
      "18:05\n",
      "you'd be like\n",
      "18:06\n",
      "sometimes i had to go to bed at night\n",
      "18:08\n",
      "because i had to get\n",
      "18:10\n",
      "up at night\n",
      "18:11\n",
      "sometimes i had to get up at night\n",
      "18:13\n",
      "because i had to go to bed at night\n",
      "18:14\n",
      "because i had to get up at night\n",
      "18:16\n",
      "because i had to get up at night\n",
      "18:18\n",
      "and it's like i don't i don't want to\n",
      "18:20\n",
      "have to go to bed at night i don't\n",
      "18:22\n",
      "like it\n",
      "18:23\n",
      "you know what i think\n",
      "18:25\n",
      "i think i think for everybody\n",
      "18:26\n",
      "it's like we're all just having a\n",
      "18:28\n",
      "day i think like a bunch of us are\n",
      "18:30\n",
      "just so bored in our own little worlds\n",
      "18:32\n",
      "where we're not gonna do anything\n",
      "18:34\n",
      "for a while and then we're like oh\n",
      "18:36\n",
      "dude we should do something\n",
      "18:38\n",
      "that's interesting\n",
      "18:40\n",
      "and then we do it and then we're\n",
      "18:41\n",
      "like oh yeah it's like\n",
      "18:44\n",
      "yeah it's like we're in the corner\n",
      "18:45\n",
      "and then we're like yeah\n",
      "18:46\n",
      "dude it's like back in the day\n",
      "18:48\n",
      "before the internet yeah it's like\n",
      "18:49\n",
      "we're in the corner when we're like\n",
      "18:50\n",
      "[ __ ] our favorite podcast\n",
      "18:52\n",
      "is like it's called uh a podcast\n",
      "18:53\n",
      "and we're like oh\n",
      "18:55\n",
      "i don't know if you've heard it\n",
      "18:56\n",
      "but uh\n",
      "18:57\n",
      "it's like a little podcast that\n",
      "18:58\n",
      "we all secretly love and we all\n",
      "18:59\n",
      "all secretly hate but we all secretly\n",
      "19:01\n",
      "love our favorite podcast and then\n",
      "19:02\n",
      "we get together and we all get together\n",
      "19:04\n",
      "and we talk about what we're doing\n",
      "19:06\n",
      "in our lives right now and we get together\n",
      "19:07\n",
      "and we get together and we make a\n",
      "19:08\n",
      "list and then it's like what are we\n",
      "19:09\n",
      "doing on our list right now\n",
      "19:11\n",
      "and then it's like hey what's your\n",
      "19:12\n",
      "favorite podcast and we're like\n",
      "19:14\n",
      "you know what we're gonna say\n",
      "19:16\n",
      "we're gonna say uh\n",
      "19:17\n",
      "we're gonna say uh we're gonna say\n",
      "19:19\n",
      "that's right and then you're like oh\n",
      "19:21\n",
      "what a great idea because then\n",
      "19:22\n",
      "it's like we're gonna figure out\n",
      "19:24\n",
      "what we're doing in our lives right\n",
      "19:27\n",
      "now and then we're gonna make a\n",
      "19:28\n",
      "list and then we're gonna add it\n",
      "19:30\n",
      "together and then we're gonna rank\n",
      "19:31\n",
      "everyone's podcast on a scale of\n",
      "19:33\n",
      "how we feel like we're doing it right\n",
      "19:34\n",
      "now and then we're gonna rank\n",
      "19:36\n",
      "the top 20 podcasts on that list\n",
      "19:37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1') # no prefix, unconditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00\n",
      "so\n",
      "00:00\n",
      "it's a\n",
      "00:01\n",
      "it's a\n",
      "00:02\n",
      "black market for\n",
      "00:04\n",
      "sizes that are\n",
      "00:05\n",
      "not sold anymore i think\n",
      "00:07\n",
      "i've never actually seen a body builder\n",
      "00:08\n",
      "make a ton of money i think\n",
      "00:10\n",
      "it's just a little bit of a\n",
      "00:11\n",
      "disappointment that we're not\n",
      "00:12\n",
      "still talking about this\n",
      "00:14\n",
      "the body builder market i think\n",
      "00:15\n",
      "it's probably lower than it was\n",
      "00:17\n",
      "last year because i think some\n",
      "00:19\n",
      "of the guys are realizing\n",
      "00:21\n",
      "that if they just kind of work\n",
      "00:23\n",
      "harder and then they can make\n",
      "00:25\n",
      "a little bit more money it will\n",
      "00:26\n",
      "also help them be more successful\n",
      "00:29\n",
      "and also maybe they'll get a little\n",
      "00:31\n",
      "bit more love because i think it\n",
      "00:33\n",
      "isn't like guys are like we're\n",
      "00:35\n",
      "hustlin and we're doing it to make\n",
      "00:37\n",
      "money\n",
      "00:38\n",
      "so to not sell out all the time\n",
      "00:40\n",
      "it's a little bit more of a\n",
      "00:42\n",
      "disappointment because you want\n",
      "00:44\n",
      "to sell out but i think the\n",
      "00:46\n",
      "market is kind of saturated right\n",
      "00:48\n",
      "now i think it's probably more\n",
      "00:50\n",
      "so saturated than ever it's just\n",
      "00:52\n",
      "more attractive right now because\n",
      "00:54\n",
      "of the number of companies\n",
      "00:55\n",
      "elsewhere that have done it and\n",
      "00:57\n",
      "because it's still sort of a\n",
      "00:59\n",
      "nerdy subculture it's still sort\n",
      "00:59\n",
      "of a niche it's just a little\n",
      "01:01\n",
      "more accessible and now the\n",
      "01:03\n",
      "market is definitely there for you\n",
      "01:05\n",
      "but i think you're a dead market\n",
      "01:07\n",
      "i think the market's dead\n",
      "01:08\n",
      "i think the market's dead yeah\n",
      "01:10\n",
      "what's the word he's dead i think\n",
      "01:12\n",
      "the word dead that's what i'm\n",
      "01:14\n",
      "thinking\n",
      "01:15\n",
      "it's dead dead dead it's dead\n",
      "01:18\n",
      "dead\n",
      "01:19\n",
      "it's dead dead dead\n",
      "01:20\n",
      "yeah but it's the last one of the\n",
      "01:22\n",
      "series after heads\n",
      "01:23\n",
      "the last one of the no i don't\n",
      "01:25\n",
      "remember the last one of the no\n",
      "01:26\n",
      "so so it's not like it's like\n",
      "01:28\n",
      "this big [ __ ] it's not like\n",
      "01:30\n",
      "right like a big [ __ ] exclusive\n",
      "01:31\n",
      "brand is big enough to hold it's\n",
      "01:33\n",
      "there\n",
      "01:34\n",
      "like a [ __ ] exclusive brand\n",
      "01:37\n",
      "but let's say it's a brand that\n",
      "01:38\n",
      "broke into the market and it's\n",
      "01:39\n",
      "came out with a product and then\n",
      "01:42\n",
      "it's like oh this is the\n",
      "01:43\n",
      "last one and then like they just\n",
      "01:44\n",
      "like they're like we're going to\n",
      "01:46\n",
      "like take this brand we're kind\n",
      "01:47\n",
      "of like not going to do a lot of\n",
      "01:49\n",
      "anymore and it's like we're like\n",
      "01:50\n",
      "i don't even know i'm a little\n",
      "01:52\n",
      "broke\n",
      "01:53\n",
      "like it's like a [ __ ] exclusive\n",
      "01:55\n",
      "brand but i don't even know\n",
      "01:57\n",
      "if it's there anymore i think it\n",
      "01:59\n",
      "was a little bit it was a little\n",
      "02:00\n",
      "little bit it was a little bit\n",
      "02:01\n",
      "pretty weird yeah but it was a\n",
      "02:02\n",
      "little bit in the niche market\n",
      "02:03\n",
      "i don't know\n",
      "02:06\n",
      "there's a new one that's just\n",
      "02:08\n",
      "bigger\n",
      "02:10\n",
      "that's the first one i'm going to\n",
      "02:11\n",
      "go to the [ __ ] exclusive\n",
      "02:12\n",
      "brand guys\n",
      "02:15\n",
      "if you're strong enough you can do\n",
      "02:17\n",
      "better than the brand you're a\n",
      "02:19\n",
      "brand\n",
      "02:20\n",
      "everybody's brand i'm a brand\n",
      "02:21\n",
      "everybody's brand is a brand yeah\n",
      "02:23\n",
      "it's a brand that's a brand\n",
      "02:24\n",
      "they're using a lot of their\n",
      "02\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name='run1', prefix=\"00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oF4-PqF0Fl7R",
    "tags": []
   },
   "source": [
    "## Notes\n",
    "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
    "\n",
    "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
    "\n",
    "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
    "\n",
    "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
    "\n",
    "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
    "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
    "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
    "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
    "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
    "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8DKMc0fiej4N",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "490a4648-d973-4675-cf9a-7a48c16fd736",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:00\n",
      "and i was\n",
      "05:00\n",
      "like i'm not june's\n",
      "05:01\n",
      "friend\n",
      "05:02\n",
      "i'm not gonna wait\n",
      "05:04\n",
      "one more week and i'm like\n",
      "05:06\n",
      "like it's funny to me that\n",
      "05:07\n",
      "you're like i'm a part of your\n",
      "05:08\n",
      "life\n",
      "05:09\n",
      "they're your friends\n",
      "05:10\n",
      "and i'm like i don't want to\n",
      "05:12\n",
      "be part of your life anymore\n",
      "05:13\n",
      "and i was like whoa\n",
      "05:15\n",
      "and i was like all right\n",
      "05:16\n",
      "hehe i don't think i need to\n",
      "05:18\n",
      "hear you say this anymore but\n",
      "05:20\n",
      "yeah i have these\n",
      "05:22\n",
      "animals on my computer\n",
      "05:24\n",
      "that i play and i have these\n",
      "05:26\n",
      "animals in the background that\n",
      "05:28\n",
      "wait\n",
      "05:29\n",
      "wait all the time\n",
      "05:31\n",
      "i have one i will say that it's\n",
      "05:33\n",
      "not a good one but i've played\n",
      "05:34\n",
      "a lot of\n",
      "====================\n",
      "00:00\n",
      "so i just wanted\n",
      "00:00\n",
      "to know that you know we\n",
      "00:02\n",
      "had a good time\n",
      "00:03\n",
      "in the car\n",
      "00:05\n",
      "so i got there i'm like\n",
      "00:06\n",
      "i think it was like like a couple\n",
      "00:07\n",
      "hours ago you said we were\n",
      "00:08\n",
      "together after like two or three\n",
      "00:09\n",
      "hours of like getting to know each\n",
      "00:10\n",
      "other and yeah\n",
      "00:11\n",
      "i did not like it at all i\n",
      "00:12\n",
      "had a lot of problems with it\n",
      "00:14\n",
      "it was like i was like yeah i\n",
      "00:15\n",
      "was like i'm literally the worst\n",
      "00:17\n",
      "performers and then i just i was\n",
      "00:18\n",
      "like i think it's\n",
      "00:20\n",
      "like the worst\n",
      "00:22\n",
      "it was the worst\n",
      "00:23\n",
      "and then you're in the back of\n",
      "00:25\n",
      "the car you're like i'm the worst\n",
      "00:27\n",
      "performers and then you're like yeah\n",
      "00:28\n",
      "no i'm the worst\n",
      "00:30\n",
      "and then you\n",
      "====================\n",
      "00:00\n",
      "and you're like\n",
      "00:00\n",
      "you're like yeah i think i think\n",
      "00:01\n",
      "that is a very good analogy it's\n",
      "00:02\n",
      "not a compliment but it's a very\n",
      "00:03\n",
      "good analogy but you're part human\n",
      "00:04\n",
      "that's what i was going for and i\n",
      "00:05\n",
      "was not being that yeah i'm not\n",
      "00:06\n",
      "actually in the fox business because\n",
      "00:07\n",
      "it's a business and it's very\n",
      "00:08\n",
      "different yeah i don't know if you\n",
      "00:10\n",
      "know this but i'm a little weird\n",
      "00:12\n",
      "like i'm like you know what i'm\n",
      "00:13\n",
      "not a fox and i'm like i'm weird\n",
      "00:15\n",
      "and then he's like i'm like a\n",
      "00:16\n",
      "human\n",
      "00:18\n",
      "and i'm like i don't know\n",
      "00:20\n",
      "and then he's like a fox i'm like\n",
      "00:21\n",
      "i'm a fox and he's like\n",
      "00:23\n",
      "i'm like i'm not a fox i'm a\n",
      "00:24\n",
      "human\n",
      "00:25\n",
      "\n",
      "====================\n",
      "00:00\n",
      "that's true i\n",
      "00:01\n",
      "thought were these the same\n",
      "00:02\n",
      "people i was talking about earlier\n",
      "00:04\n",
      "i'm glad you brought up that\n",
      "00:05\n",
      "because i'm curious a lot of\n",
      "00:06\n",
      "these comments are like yeah he\n",
      "00:07\n",
      "walks around i'm like oh he's such\n",
      "00:09\n",
      "a cool dude you're like i don't really\n",
      "00:11\n",
      "like talking to you you're like i'm\n",
      "00:12\n",
      "like i'm like [ __ ] you know\n",
      "00:14\n",
      "that's an old joke about people\n",
      "00:15\n",
      "who would say to a bald guy who's\n",
      "00:17\n",
      "getting near but they're bald and\n",
      "00:18\n",
      "they're like we've been in the\n",
      "00:19\n",
      "club the whole time and it's like\n",
      "00:21\n",
      "yeah but it's like we've been\n",
      "00:22\n",
      "there the whole time and we're like\n",
      "00:23\n",
      "yeah but he's like no we went to\n",
      "00:24\n",
      "tiger mom\n",
      "00:26\n",
      "i'm curious because you're like\n",
      "00:27\n",
      "i'm\n",
      "====================\n",
      "00:00\n",
      "you're only 11 and you're like\n",
      "00:01\n",
      "like trying to make parents laugh\n",
      "00:02\n",
      "and then you can't help yourself\n",
      "00:03\n",
      "who's listening and you're like what\n",
      "00:04\n",
      "is this yeah you're not gonna like you\n",
      "00:05\n",
      "don't i'm gonna be like i need to\n",
      "00:06\n",
      "get some help you are not listening\n",
      "00:07\n",
      "this is the worst you are not listening\n",
      "00:09\n",
      "you're not listening what are you\n",
      "00:10\n",
      "doing this is the worst this is the\n",
      "00:12\n",
      "worst you are not listening you're\n",
      "00:13\n",
      "like oh please help me i'm so\n",
      "00:14\n",
      "complicated you're not listening this\n",
      "00:15\n",
      "is the worst in a while yeah\n",
      "00:16\n",
      "this is the worst in a while oh you\n",
      "00:17\n",
      "are not listening\n",
      "00:18\n",
      "you're not listening you're not\n",
      "00:19\n",
      "listening to this\n",
      "00:21\n",
      "literally not listening to this\n",
      "00:23\n",
      "because it's like it's like it's\n",
      "00:24\n",
      "funny that you're\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess,\n",
    "              length=250,\n",
    "              temperature=0.7,\n",
    "              prefix=\"00:00\",\n",
    "              nsamples=5,\n",
    "              batch_size=5\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjjEN2Tafhl2"
   },
   "source": [
    "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
    "\n",
    "You can rerun the cells as many times as you want for even more generated texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Fa6p6arifSL0"
   },
   "outputs": [],
   "source": [
    "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
    "\n",
    "gpt2.generate_to_file(sess,\n",
    "                      destination_path=gen_file,\n",
    "                      length=500,\n",
    "                      temperature=0.7,\n",
    "                      prefix=\"00:00\",\n",
    "                      nsamples=100,\n",
    "                      batch_size=20\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-LRex8lfv1g"
   },
   "source": [
    "Download the file by hand in the browser at left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTa6zf3e_9gV"
   },
   "source": [
    "Uploaded your saved checkpoint and unzip it.\n",
    "\n",
    "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
    "\n",
    "This will reset or start the tensorflow session as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fxL77nvAMAX",
    "outputId": "8938432a-3b86-4102-f32b-362721ecb897"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "if not sess:\n",
    "    sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "    sess = gpt2.reset_session(sess)\n",
    "\n",
    "gpt2.load_gpt2(sess, run_name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig-KVgkCDCKD"
   },
   "source": [
    "# Etcetera\n",
    "\n",
    "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIHiVP53FnsX"
   },
   "outputs": [],
   "source": [
    "!kill -9 -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmTXWNUygS5E"
   },
   "source": [
    "# License\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2019 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- Max's [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
    "- Original repo: [gpt-2-simple](https://github.com/minimaxir/gpt-2-simple) by [Max Woolf](http://minimaxir.com). \n",
    "- Original [google colab](https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce) from Max."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Train a GPT-2 Text-Generating Model w/ GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow GPU 2.6 (py39)",
   "language": "python",
   "name": "tensorflow-gpu-2.6-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
